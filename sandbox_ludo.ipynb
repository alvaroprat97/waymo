{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import torch\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# CONFIG\n",
    "data_path = os.getcwd() + \"/data/training/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blob(blob_idx):\n",
    "    with open(f'{data_path}FRONT/blob_0_frame_0.pickle', 'rb') as f:\n",
    "        # Load the 'data' dictionary using the highest protocol available.\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# import time\n",
    "# start = time.time()\n",
    "blob = load_blob(1)\n",
    "# end = time.time()\n",
    "# print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# torch.tensor(np.array(bytearray(blob[0]['SIDE_RIGHT']['image']))).shape\n",
    "x = tf.image.decode_jpeg(blob[0]['SIDE_RIGHT']['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(x.numpy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob[0]['FRONT']['labels'].labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob[0]['FRONT']['labels'].labels[2].box.center_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pickle\n",
    "\n",
    "tf.enable_eager_execution() # No need for session to be created. Function instances are run immediately. \n",
    "\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from google.cloud import storage\n",
    "\n",
    "import concurrent.futures as concurr\n",
    "\n",
    "# CONFIG\n",
    "project = \"Waymo3DObjectDetection\"\n",
    "bucket_name = 'waymo_open_dataset_v_1_2_0_individual_files'\n",
    "suffix = '.tfrecord'\n",
    "data_destination = os.getcwd() + \"/data/\"\n",
    "download_batch_size = 1\n",
    "\n",
    "def download_blob(blob, c):\n",
    "    \"\"\"\n",
    "    blob = single file name\n",
    "    c = file counter\n",
    "    \"\"\"\n",
    "    fname = f\"{data_destination}blob_{c}{suffix}\"\n",
    "    blob.download_to_filename(fname)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a client\n",
    "storage_client = storage.Client(project= project) #storage.Client(project= \"Waymo3DObjectDetection\", credentials=credentials)\n",
    "# Create a bucket object for our bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "# Get blob files in bucket\n",
    "blobs = [blob for blob in storage_client.list_blobs(bucket_name, prefix='training/')]\n",
    "\n",
    "n_blobs = len(blobs) # Number of blobs in the training dataset\n",
    "print(f'Total number of blobs is {n_blobs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob(blobs[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_blob = '/home/project_x/data/blob_0.tfrecord'\n",
    "dataset = tf.data.TFRecordDataset(downloaded_blob, compression_type='')\n",
    "frames = []\n",
    "for idx, data in enumerate(dataset):\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    print(len(frame.camera_labels))\n",
    "    frames.append(frame)\n",
    "    # Function to strip away LIDAR and other garbage from frame\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame.camera_labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in frames:\n",
    "    print(i.camera_labels[5].name)\n",
    "        for i, camera in enumerate([\"FRONT\", \"FRONT_LEFT\", \"SIDE_LEFT\", \"FRONT_RIGHT\", \"SIDE_RIGHT\"]):\n",
    "\n",
    "\"blob_1_frame_19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3,4,5,6 ,7][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200*800/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir FRONT\n",
    "mkdir SIDE_RIGHT\n",
    "mkdir FRONT_LEFT\n",
    "mkdir FRONT_RIGHT\n",
    "mkdir SIDE_LEFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data/training/FRONT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import tensorflow.compat.v1 as tf\n",
    "CAMERAS = [\"FRONT\", \"FRONT_LEFT\", \"SIDE_LEFT\", \"FRONT_RIGHT\", \"SIDE_RIGHT\"]\n",
    "BIG_X = 1280\n",
    "SMALL_X = 886\n",
    "Y_DIM = 1920\n",
    "\n",
    "class WaymoDataset(Dataset):\n",
    "    \"\"\"Dataset for image segmentation and regression.\"\"\"\n",
    "\n",
    "    def __init__(self, scope='training', cameras=CAMERAS, order='random', exclusions=None, heatmaps=True):\n",
    "        \n",
    "        self.heatmaps = heatmaps\n",
    "\n",
    "        # Create list of all filepaths\n",
    "        self.filepaths = []\n",
    "        root_path = os.getcwd() + f'/data/{scope}'\n",
    "        for cam in CAMERAS:\n",
    "            cam_filepaths = os.listdir(f'{root_path}/{cam}')\n",
    "            self.filepaths += [f'{root_path}/{cam}/{i}' for i in cam_filepaths]\n",
    "\n",
    "        # Filter exclusions\n",
    "        if exclusions is not None:\n",
    "            self.filepaths = [i for i in self.filepaths if not any(j in i for j in exclusions)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        fpath = self.filepaths[item]\n",
    "        sample = load_pickle(fpath)\n",
    "        img = torch.tensor(\n",
    "            tf.image.decode_jpeg(sample['image']).numpy())\n",
    "\n",
    "        cam_type = fpath.split('/')[5] # FRONT, SIDE_LEFT etc\n",
    "        labels = scale_labels(sample['labels'].labels, cam_type)\n",
    "        if self.heatmaps:\n",
    "            labels = convert_to_heatmap(labels)\n",
    "\n",
    "        return {'img': img, 'labels' : labels}\n",
    "\n",
    "\n",
    "    def get_context(self, item):\n",
    "        return self.img_names[item]\n",
    "\n",
    "def scale_labels(labels, cam='FRONT'):\n",
    "    if cam in ['SIDE_LEFT', 'SIDE_RIGHT']:\n",
    "        x_dim = BIG_X\n",
    "    else:\n",
    "        x_dim = SMALL_X\n",
    "    res = {i+1:[] for i in range(4)}\n",
    "    for i in labels:\n",
    "        res[i.type].append({\n",
    "            'id': i.id,\n",
    "            'x': i.box.center_x/x_dim,\n",
    "            'y': i.box.center_y/Y_DIM,\n",
    "            'width': i.box.width/x_dim,\n",
    "            'length': i.box.length/Y_DIM\n",
    "        })\n",
    "    return res\n",
    "def load_pickle(fpath):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def convert_to_heatmap(img_dims, labels):\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "wD = WaymoDataset(cameras=['FRONT'], heatmaps=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(wD,\n",
    "                                    batch_size=4, shuffle=True,\n",
    "                                    um_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: FRONT\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 916.963565864244\n",
       "    center_y: 689.1694420615702\n",
       "    width: 18.00022448145353\n",
       "    length: 15.57915965430243\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"088fc0a9-a56e-46f1-b975-13b557c951df\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 608.4022651186859\n",
       "    center_y: 773.8779320734784\n",
       "    width: 103.30981203028102\n",
       "    length: 139.4908225918482\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"3207b332-ca3b-4e67-850a-7572a023ed5e\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 1123.2820572662786\n",
       "    center_y: 749.0652348441859\n",
       "    width: 104.21235000000001\n",
       "    length: 124.10728345325583\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"4438e317-45d5-4318-880d-928f72d6ae80\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 903.489533682083\n",
       "    center_y: 689.6962247398812\n",
       "    width: 20.210879999999975\n",
       "    length: 24.947810526011835\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"46be34fb-7879-4755-a73f-03e5339592f5\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 862.2467139762578\n",
       "    center_y: 702.833288340566\n",
       "    width: 35.36905768317604\n",
       "    length: 45.60079092672959\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"7d5512ac-7f6c-4b5f-a89b-cfb01724948b\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 1016.22831\n",
       "    center_y: 689.0646899999999\n",
       "    width: 29.053139999999985\n",
       "    length: 30.94790999999998\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"a5d40eb7-c301-4fb0-be51-5e167d9a761f\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 749.69733\n",
       "    center_y: 733.2759899999999\n",
       "    width: 73.89603\n",
       "    length: 88.42259999999999\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"ae414db0-1fe3-4730-8ddb-8b81083f2d33\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 497.69534474790794\n",
       "    center_y: 808.1183441727903\n",
       "    width: 145.26448762604605\n",
       "    length: 212.52897417279019\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"cabc0cf5-b090-4180-88d6-ad40a79d2da5\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 882.015473682083\n",
       "    center_y: 694.11732158381\n",
       "    width: 32.84267999999997\n",
       "    length: 41.05335000000002\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"d47ec43b-156b-484b-9afe-6fd2d3895cee\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 1068.6502800000003\n",
       "    center_y: 731.38122\n",
       "    width: 61.26423\n",
       "    length: 60.63264000000004\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"e0a453c7-b8ed-4452-935f-9cc0a159faf8\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 1061.5443948015418\n",
       "    center_y: 711.0116385255675\n",
       "    width: 59.21152421550323\n",
       "    length: 74.36937793952893\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"f05a5227-7e7a-432d-b8a3-fe761b180af9\"\n",
       "}\n",
       "labels {\n",
       "  box {\n",
       "    center_x: 296.84911856093095\n",
       "    center_y: 739.5911827818602\n",
       "    width: 62.52710690651156\n",
       "    length: 198.950243813023\n",
       "  }\n",
       "  type: TYPE_VEHICLE\n",
       "  id: \"fd39c650-f8fe-4cc2-858e-394a73fb97aa\"\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_pickle(wD.filepaths[0])['labels']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
