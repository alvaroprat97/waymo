{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('models/efficientdet/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from src.dataset import WaymoDataset, Resizer, Normalizer\n",
    "wd = WaymoDataset(cameras=['FRONT'], scope='validation', transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "model = torch.load('trained_models/signatrix_efficientdet_coco.pth',\n",
    "          map_location=torch.device('cpu')).module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from src.dataset import CocoDataset, Resizer, Normalizer\n",
    "from src.config import COCO_CLASSES, colors\n",
    "import cv2\n",
    "import shutil\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "dataset = wd\n",
    "model = ed\n",
    "\n",
    "for index in range(1):\n",
    "    data = dataset[index]\n",
    "    scale = data['scale']\n",
    "    with torch.no_grad():\n",
    "        scores, labels, boxes = model(data['img'].permute(2, 0, 1).float().unsqueeze(dim=0))\n",
    "        boxes /= scale\n",
    "    if boxes.shape[0] > 0:\n",
    "        \n",
    "        output_image = tf.image.decode_jpeg(data['raw'][\"image\"]).numpy()\n",
    "#         output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "        for box_id in range(boxes.shape[0]):\n",
    "            pred_prob = float(scores[box_id])\n",
    "            if pred_prob < 0.3:\n",
    "                break\n",
    "            pred_label = int(labels[box_id])\n",
    "            xmin, ymin, xmax, ymax = boxes[box_id, :]\n",
    "            color = colors[pred_label]\n",
    "            cv2.rectangle(output_image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color, 15)\n",
    "            text_size = cv2.getTextSize(COCO_CLASSES[pred_label] + ' : %.2f' % pred_prob, cv2.FONT_HERSHEY_PLAIN, 2, 1)[0]\n",
    "\n",
    "#             cv2.rectangle(output_image, (xmin, ymin), (xmin + text_size[0] +100, ymin + text_size[1] - 100), colors[pred_label+1], -1)\n",
    "            cv2.putText(\n",
    "                output_image, COCO_CLASSES[pred_label] + ' : %.2f' % pred_prob,\n",
    "                (xmin, ymin + text_size[1] - 40), cv2.FONT_HERSHEY_PLAIN, 5,\n",
    "                (255, 255, 255), 3)\n",
    "\n",
    "        plt.imshow( output_image)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "x = tf.image.decode_jpeg(wd[0]['raw'][\"image\"]).numpy()\n",
    "plt.imshow(x)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('fig.jpg',bbox_inches='tight',transparent=True, pad_inches=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = x\n",
    "# output_image = cv2.cvtColor(output_image)\n",
    "labels = wd[0]['raw']['labels'].labels\n",
    "for box_id in range(len(labels)):\n",
    "    label = labels[box_id]\n",
    "    box = label.box\n",
    "    pred_label = label.type\n",
    "    xy1=(label.box.center_x - 0.5 * label.box.length,\n",
    "                label.box.center_y - 0.5 * label.box.width)\n",
    "    xy2=(label.box.center_x + 0.5 * label.box.length,\n",
    "                label.box.center_y + 0.5 * label.box.width)\n",
    "    xmin, ymin = (int(i) for i in xy1)\n",
    "    xmax, ymax = (int(i) for i in xy2)\n",
    "    color = colors[pred_label]\n",
    "    cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "    text_size = cv2.getTextSize(str(pred_label) + ' : %.2f' % pred_prob, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "\n",
    "    cv2.rectangle(output_image, (xmin, ymin), (xmin, ymin), color, -1)\n",
    "#     cv2.putText(\n",
    "#         output_image, COCO_CLASSES[pred_label] + ' : %.2f' % pred_prob,\n",
    "#         (xmin, ymin + text_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "#         (255, 255, 255), 1)\n",
    "plt.imshow( output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/project_x/evaluation/waymo-od/waymo_open_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd[5]['raw']['context']\n",
    "debox = lambda x: [x.center_x, x.center_y, x.width, x.length]\n",
    "frame = wd[5]['raw']\n",
    "labels = frame['labels'].labels\n",
    "num_boxes = len(labels)\n",
    "pred_frame_id = [\n",
    "    frame['context']['name']+ frame[\n",
    "        'context'][\n",
    "        'time_frame_idx'] for _ in range(num_boxes)\n",
    "                ]\n",
    "pred_bbox = [debox(i.box) for i in labels]\n",
    "pred_type = [i.type for i in labels]\n",
    "pred_score = [1 for i in range(num_boxes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i, s in enumerate(wd.filepaths) if 'blob_130' in s] # 0,105,167\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from waymo_open_dataset.protos import metrics_pb2\n",
    "from waymo_open_dataset import label_pb2,dataset_pb2\n",
    "\n",
    "# ['vehicle', 'pedestrian', 'sign', 'cyclist']\n",
    "# Could have included things like boat, train, airplane (vehicles?)\n",
    "class_mapper = {\n",
    "    0: 2, # person\n",
    "    1:4, # in COCO it's bicycle not cyclist...\n",
    "    2:1, # car\n",
    "    3:1, # motorcycle\n",
    "    5:1, # bus\n",
    "    7:1, # truck\n",
    "    11:3 # stop sign\n",
    "}\n",
    "score_threshold = 0.4 \n",
    "def get_preds(sample, model):\n",
    "    with torch.no_grad():\n",
    "        scores, annot, boxes = model(sample['img'].permute(2, 0, 1).float().unsqueeze(dim=0))\n",
    "        boxes /= sample['scale']\n",
    "    return scores, annot, boxes\n",
    "def convert_to_waymo_boxes(boxes):\n",
    "    tb = boxes.T\n",
    "    length = tb[2]-tb[0]\n",
    "    width = tb[3]-tb[1]\n",
    "    tb[0] = tb[2]-length # center x\n",
    "    tb[1] = tb[3]-width # center y\n",
    "    tb[2] = length\n",
    "    tb[3] = width\n",
    "    res = tb.T\n",
    "    return res\n",
    "def gt_map(o, data):\n",
    "    box = label_pb2.Label.Box()\n",
    "    box.center_x = data.box.center_x\n",
    "    box.center_y = data.box.center_y\n",
    "    box.length = data.box.length\n",
    "    box.width = data.box.width\n",
    "\n",
    "    o.object.box.CopyFrom(box)\n",
    "    o.score = 1\n",
    "    # Use correct type.\n",
    "    o.object.type = data.type\n",
    "def pred_map(o, data):\n",
    "    s, c, b = data\n",
    "    box = label_pb2.Label.Box()\n",
    "    box.center_x = b[0]\n",
    "    box.center_y = b[1]\n",
    "    box.length = b[2]\n",
    "    box.width = b[3]\n",
    "    o.object.box.CopyFrom(box)\n",
    "    o.score = s\n",
    "    # Use correct type.\n",
    "    o.object.type = class_mapper[c.item()]\n",
    "def filter_preds(data):\n",
    "    scores, classes, boxes = data\n",
    "    valid_idxs = []\n",
    "    for c,cls in enumerate(classes):\n",
    "        if (cls in [0,1,2,3, 5,7,11])*(scores[c]>score_threshold):\n",
    "            valid_idxs.append(c)\n",
    "    valid_idxs = torch.tensor(valid_idxs).long()\n",
    "    scores = scores.index_select(0, valid_idxs)\n",
    "    classes = classes.index_select(0, valid_idxs)\n",
    "    boxes = boxes.index_select(0, valid_idxs)\n",
    "    return (scores, classes, boxes)\n",
    "def process_frame_objects(objects, data, name, ts, cam, scope):\n",
    "    if scope=='preds':\n",
    "        data = filter_preds(data)\n",
    "        num_objects = len(data[0])\n",
    "        boxes = convert_to_waymo_boxes(data[2])\n",
    "    else:\n",
    "        num_objects = len(data)\n",
    "    for c in range(num_objects):\n",
    "        o = metrics_pb2.Object()\n",
    "        o.context_name = name\n",
    "        o.frame_timestamp_micros = ts\n",
    "        o.camera_name = cam = cam\n",
    "        if scope=='preds':\n",
    "            data_i = (data[0][c], data[1][c], boxes[c]) # scores, classes, boxes\n",
    "            pred_map(o, data_i)\n",
    "        else:\n",
    "            gt_map(o, data[c])\n",
    "        objects.objects.append(o)\n",
    "\n",
    "def create_pd_file(dataset, model): # preds or gt\n",
    "    \"\"\"Creates a prediction objects file.\"\"\"\n",
    "    gt_objects = metrics_pb2.Objects()\n",
    "    pred_objects = metrics_pb2.Objects()\n",
    "    for c, item in enumerate(dataset):\n",
    "        preds = get_preds(item, model)\n",
    "        ctx = item['raw']['context']\n",
    "        cam = getattr(dataset_pb2.CameraName, dataset.get_cam_type(c))\n",
    "        # Populate preds\n",
    "        process_frame_objects(pred_objects, preds, ctx['name'],\n",
    "                              ctx['timestamp'], cam, 'preds')\n",
    "        process_frame_objects(gt_objects, item['raw']['labels'].labels, ctx['name'],\n",
    "                              ctx['timestamp'], cam, 'gt')        \n",
    "        if c%2==0:\n",
    "            print(f'Processed {c} frames out of {len(dataset)}')\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    # Write objects to a file.\n",
    "    f = open('/home/project_x/evaluation/results/preds.bin', 'wb')\n",
    "    f.write(pred_objects.SerializeToString())\n",
    "    f.close()\n",
    "    f = open('/home/project_x/evaluation/results/gt.bin', 'wb')\n",
    "    f.write(gt_objects.SerializeToString())\n",
    "    f.close()\n",
    "create_pd_file(wd, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.index_select(0, torch.tensor([5,3,10, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['raw']['labels'].labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from waymo_open_dataset import metrics_pb2\n",
    "# y = label_pb2.Label\n",
    "# y.TYPE_CYCLIST\n",
    "from waymo_open_dataset import dataset_pb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(dataset_pb2.CameraName, wd.get_cam_type(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([5]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bazel-bin/waymo_open_dataset/metrics/tools/compute_detection_metrics_main /home/project_x/evaluation/results/preds.bin  /home/project_x/evaluation/results/gt.bin\n",
    "y = label_pb2.Label\n",
    "dir(y.Box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pb2.Label.TYPE_CYCLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
