{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "import torch\n",
    "\n",
    "tf.enable_eager_execution() # No need for session to be created. Function instances are run immediately. \n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from google.cloud import storage\n",
    "\n",
    "import concurrent.futures as concurr\n",
    "\n",
    "# CONFIG\n",
    "project = \"Waymo3DObjectDetection\"\n",
    "bucket_name = 'waymo_open_dataset_v_1_2_0_individual_files'\n",
    "suffix = '.tfrecord'\n",
    "data_destination = os.getcwd() + \"/data/\"\n",
    "download_batch_size = 1\n",
    "\n",
    "def partition(list_in, n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "# def download_batch(blobs, batch_num=0):\n",
    "#     fnames = []\n",
    "#     for c, blob in enumerate(blobs):\n",
    "#         fname = f\"{data_destination}batch_{batch_num}file_{c}{suffix}\"\n",
    "#         print(blob)\n",
    "#         blob.download_to_filename(fname)\n",
    "#         fnames.append(fname)\n",
    "#     return fnames\n",
    "\n",
    "def download_blob(blob, c, batch_num=0):\n",
    "    \"\"\"\n",
    "    blob = single file name\n",
    "    c = file counter\n",
    "    \"\"\"\n",
    "    fname = f\"{data_destination}batch_{batch_num}file_{c}{suffix}\"\n",
    "    blob.download_to_filename(fname)\n",
    "    print(f'File {c} of batch {batch_num} has downloaded')\n",
    "    return fname\n",
    "\n",
    "# Initialise a client\n",
    "storage_client = storage.Client(project= project) #storage.Client(project= \"Waymo3DObjectDetection\", credentials=credentials)\n",
    "# Create a bucket object for our bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "# Get blob files in bucket\n",
    "blobs = [blob for blob in storage_client.list_blobs(bucket_name, prefix='training/')]\n",
    "# Partition files into batches\n",
    "# batch_num = int(len(blobs)/download_batch_size)\n",
    "# batches = partition(blobs, batch_num)\n",
    "\n",
    "# Eventually will look like this\n",
    "# for c, batch in enumerate(batches):\n",
    "#     fnames = download_batch(batch, c)\n",
    "#     dataset = tf.data.TFRecordDataset(fname, compression_type='')\n",
    "    # DO SOMETHING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def _strip_frame(frame, idx, blob_idx):\n",
    "    \"\"\"Strip frame from garbage such as LIDAR data\"\"\"\n",
    "    \n",
    "    cam_dict = {}\n",
    "    for i, camera in enumerate([\"FRONT\", \"FRONT_LEFT\", \"SIDE_LEFT\", \"FRONT_RIGHT\", \"SIDE_RIGHT\"]):\n",
    "        cam_dict[camera] = {}\n",
    "#         cam_dict[camera]['image'] = torch.tensor((tf.image.decode_jpeg(frame.images[i].image)).numpy())\n",
    "#         cam_dict[camera]['image'] = tf.image.decode_jpeg(frame.images[i].image)\n",
    "        cam_dict[camera]['image'] = frame.images[i].image\n",
    "        cam_dict[camera]['velocity'] = frame.images[i].velocity\n",
    "        cam_dict[camera]['labels'] = frame.camera_labels[i]\n",
    "        \n",
    "    cam_dict['context']={'stats':frame.context.stats, \n",
    "                       'name': frame.context.name, \n",
    "                       'blob_idx':blob_idx,\n",
    "                       'time_frame_idx':idx}\n",
    "    return cam_dict\n",
    "\n",
    "def _save_frames(frames):\n",
    "    \"\"\"Save frames into pickle format. To preprocess later\"\"\"\n",
    "    blob_idx = frames[0]['context']['blob_idx']\n",
    "    with open(f'{data_destination}pickled/blob_{blob_idx}.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(frames, f, pickle.HIGHEST_PROTOCOL)\n",
    "    return None\n",
    "\n",
    "def _load_frame(frame_idx, blob_idx):\n",
    "    with open(f'{data_destination}pickled/blob_{blob_idx}.pickle', 'rb') as f:\n",
    "        # Load the 'data' dictionary using the highest protocol available.\n",
    "        return pickle.load(f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "######################################################\n",
    "def process_frame(data, idx, blob_idx):\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    # Function to strip away LIDAR and other garbage from frame\n",
    "    return _strip_frame(frame, idx, blob_idx)\n",
    "    \n",
    "# Retrieve frames from selected files to download\n",
    "def get_frames_from_one_blob_m_thread(downloaded_blob, blob_idx):\n",
    "    # Load into tf record dataset\n",
    "    frames = []\n",
    "    dataset = tf.data.TFRecordDataset(downloaded_blob, compression_type='')\n",
    "    dset_list = [data for data in dataset]\n",
    "    idx_list = [idx for idx in range(len(dset_list))]\n",
    "    with concurr.ThreadPoolExecutor(max_workers=None) as executor:\n",
    "        results = executor.map(process_frame, dset_list, idx_list, blob_idx)\n",
    "#             frames.append(frame)\n",
    "    return results    \n",
    "######################################################\n",
    "\n",
    "# Retrieve frames from selected files to download\n",
    "def get_frames_from_one_blob(downloaded_blob, blob_idx):\n",
    "    # Load into tf record dataset\n",
    "    dataset = tf.data.TFRecordDataset(downloaded_blob, compression_type='')\n",
    "    frames = []\n",
    "    for idx, data in enumerate(dataset):\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        # Function to strip away LIDAR and other garbage from frame\n",
    "        frame = _strip_frame(frame, idx, blob_idx)\n",
    "        frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blobs is 798\n",
      "File 0 of batch 0 has downloaded\n",
      "\n",
      " Time is 16.485257148742676\n",
      "Elapsed time is 16.486326694488525\n"
     ]
    }
   ],
   "source": [
    "n_blobs = len(blobs) # Number of blobs in the training dataset\n",
    "print(f'Number of blobs is {n_blobs}')\n",
    "\n",
    "now = time.time()\n",
    "downloaded_blobs = []\n",
    "\n",
    "with concurr.ThreadPoolExecutor(max_workers = 2) as executor:\n",
    "    n1 = 0\n",
    "    n2 = 1\n",
    "    idx_list = [i for i in range(n1,n2)]\n",
    "    results = executor.map(download_blob, blobs[n1:n2], idx_list)\n",
    "    for r in results:\n",
    "        print(f'\\n Time is {time.time() - now}')\n",
    "        downloaded_blobs.append(r)\n",
    "        \n",
    "then = time.time()\n",
    "print(f'Elapsed time is {then - now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Now we just need to do in the same loop (multi-threaded):\n",
    "# 1 - download a blob\n",
    "# 2 - process the frames and save that blob\n",
    "# 3 - discard the blob and move to the next blob (memory efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE FUCKING FRAMES, we just need to loop over blobidx and that is it \n",
    "\n",
    "blobidx = 0\n",
    "frames = get_frames_from_one_blob(downloaded_blobs[blobidx], blobidx)\n",
    "_save_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_camera_image(camera_image, camera_labels, layout, cmap=None):\n",
    "    \"\"\"Show a camera image and the given camera labels.\"\"\"\n",
    "\n",
    "    ax = plt.subplot(*layout)\n",
    "\n",
    "    # Draw the camera labels.\n",
    "    for camera_label in camera_labels:\n",
    "        # Ignore camera labels that do not correspond to this camera.\n",
    "        if camera_label.name != camera_image.name:\n",
    "            continue\n",
    "            \n",
    "        for label in camera_label.labels:\n",
    "            # Draw the object bounding box.\n",
    "            ax.add_patch(patches.Rectangle(\n",
    "            xy=(label.box.center_x - 0.5 * label.box.length,\n",
    "                label.box.center_y - 0.5 * label.box.width),\n",
    "            width=label.box.length,\n",
    "            height=label.box.width,\n",
    "            linewidth=1,\n",
    "            edgecolor='red',\n",
    "            facecolor='none'))\n",
    "\n",
    "    # Show the camera image.\n",
    "    plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
    "    plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(figsize=(25, 20))\n",
    "\n",
    "for index, image in enumerate(frames[20].images):\n",
    "    show_camera_image(image, frames[20].camera_labels, [3, 3, index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithread tryout\n",
    "\n",
    "def do_something(file, idx):\n",
    "    time.sleep(idx)\n",
    "    return f'Slept for {idx} seconds'\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "with concurr.ThreadPoolExecutor(max_workers=None) as executor:\n",
    "    downloaded_blobs = []\n",
    "    n1 = 0\n",
    "    n2 = 10\n",
    "    idx_list = [i for i in range(n1,n2)]\n",
    "    results = executor.map(do_something, blobs[n1:n2], idx_list)\n",
    "    for r in results:\n",
    "        print(r)\n",
    "        downloaded_blobs.append(r)\n",
    "        \n",
    "then = time.time()\n",
    "print(f'Elapsed time is {then - now}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
